{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-1",
   "metadata": {},
   "source": [
    "# ICC-based Feature Selection for Radiomics Reproducibility Assessment\n",
    "\n",
    "## Overview\n",
    "This notebook assesses the computational reproducibility of an automated radiomics pipeline using intraclass correlation coefficients (ICC).\n",
    "\n",
    "## Method\n",
    "- **Sample**: A subset of 40 patients (120 discs) randomly selected from the entire cohort\n",
    "- **Pipeline**: Complete automated pipeline (TotalSpineSeg segmentation + PyRadiomics feature extraction) independently executed twice using identical settings\n",
    "- **ICC Model**: Two-way random effects model for absolute agreement [ICC(2,1)]\n",
    "- **Tool**: pingouin package (version 0.5.5) in Python\n",
    "- **Selection Criterion**: Features with ICC > 0.75 (excellent reproducibility) are retained for subsequent analysis\n",
    "\n",
    "## Reference\n",
    "- Koo TK, Li MY. A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research. J Chiropr Med. 2016;15(2):155-163."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-libs",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pingouin as pg\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"Pingouin version: {pg.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "**Please modify the following parameters according to your data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Configuration - Please modify according to your data\n",
    "# =============================================================================\n",
    "\n",
    "# File paths for the two independent feature extraction runs\n",
    "PATH_RUN1 = 'data/features_run1.xlsx'  # First extraction\n",
    "PATH_RUN2 = 'data/features_run2.xlsx'  # Second extraction\n",
    "\n",
    "# Non-feature columns (e.g., sample ID, labels)\n",
    "# These columns will be excluded from ICC calculation\n",
    "ID_COLUMNS = ['MASK', 'disc_degree']\n",
    "\n",
    "# ICC threshold for feature selection\n",
    "ICC_THRESHOLD = 0.75\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = 'results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Load feature data from two independent runs\n",
    "features_run1 = pd.read_excel(PATH_RUN1)\n",
    "features_run2 = pd.read_excel(PATH_RUN2)\n",
    "\n",
    "print(f\"Run 1: {features_run1.shape[0]} samples, {features_run1.shape[1]} columns\")\n",
    "print(f\"Run 2: {features_run2.shape[0]} samples, {features_run2.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preprocess",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by ID column to ensure consistent sample order\n",
    "if 'MASK' in features_run1.columns:\n",
    "    features_run1 = features_run1.sort_values('MASK').reset_index(drop=True)\n",
    "    features_run2 = features_run2.sort_values('MASK').reset_index(drop=True)\n",
    "\n",
    "# Get feature columns (excluding ID columns)\n",
    "feature_columns = [col for col in features_run1.columns if col not in ID_COLUMNS]\n",
    "\n",
    "# Validation\n",
    "assert features_run1.shape[0] == features_run2.shape[0], \"Sample counts do not match!\"\n",
    "print(f\"Number of samples: {features_run1.shape[0]}\")\n",
    "print(f\"Number of features: {len(feature_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": [
    "## 5. Calculate ICC(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "icc-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_icc(feature_name, run1_data, run2_data):\n",
    "    \"\"\"\n",
    "    Calculate ICC(2,1) for a single feature.\n",
    "    \n",
    "    ICC(2,1): Two-way random effects model for absolute agreement.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_name : str\n",
    "        Name of the feature\n",
    "    run1_data : array-like\n",
    "        Feature values from first extraction\n",
    "    run2_data : array-like\n",
    "        Feature values from second extraction\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict : Dictionary containing ICC value and confidence intervals\n",
    "    \"\"\"\n",
    "    n_subjects = len(run1_data)\n",
    "    \n",
    "    # Create long-format DataFrame for ICC calculation\n",
    "    df_long = pd.DataFrame({\n",
    "        'Subject': list(range(n_subjects)) * 2,\n",
    "        'Rater': ['Run1'] * n_subjects + ['Run2'] * n_subjects,\n",
    "        'Value': list(run1_data) + list(run2_data)\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        # Calculate ICC using pingouin\n",
    "        icc_result = pg.intraclass_corr(\n",
    "            data=df_long,\n",
    "            targets='Subject',\n",
    "            raters='Rater',\n",
    "            ratings='Value'\n",
    "        )\n",
    "        \n",
    "        # Extract ICC(2,1) results - \"ICC2\" corresponds to ICC(2,1)\n",
    "        icc2_row = icc_result[icc_result['Type'] == 'ICC2']\n",
    "        \n",
    "        if len(icc2_row) > 0:\n",
    "            return {\n",
    "                'Feature': feature_name,\n",
    "                'ICC': icc2_row['ICC'].values[0],\n",
    "                'CI95_lower': icc2_row['CI95%'].values[0][0],\n",
    "                'CI95_upper': icc2_row['CI95%'].values[0][1],\n",
    "                'F': icc2_row['F'].values[0],\n",
    "                'pval': icc2_row['pval'].values[0]\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating ICC for {feature_name}: {e}\")\n",
    "    \n",
    "    return {\n",
    "        'Feature': feature_name,\n",
    "        'ICC': np.nan,\n",
    "        'CI95_lower': np.nan,\n",
    "        'CI95_upper': np.nan,\n",
    "        'F': np.nan,\n",
    "        'pval': np.nan\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calculate-all-icc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ICC for all features\n",
    "print(\"Calculating ICC(2,1) for all features...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "icc_results = []\n",
    "\n",
    "for i, feature in enumerate(feature_columns):\n",
    "    run1_values = features_run1[feature].values\n",
    "    run2_values = features_run2[feature].values\n",
    "    \n",
    "    # Handle constant features\n",
    "    if np.std(run1_values) == 0 and np.std(run2_values) == 0:\n",
    "        result = {\n",
    "            'Feature': feature,\n",
    "            'ICC': 1.0,\n",
    "            'CI95_lower': 1.0,\n",
    "            'CI95_upper': 1.0,\n",
    "            'F': np.inf,\n",
    "            'pval': 0.0\n",
    "        }\n",
    "    else:\n",
    "        result = calculate_icc(feature, run1_values, run2_values)\n",
    "    \n",
    "    icc_results.append(result)\n",
    "    \n",
    "    if (i + 1) % 100 == 0 or (i + 1) == len(feature_columns):\n",
    "        print(f\"Progress: {i+1}/{len(feature_columns)}\")\n",
    "\n",
    "icc_df = pd.DataFrame(icc_results)\n",
    "print(\"\\nICC calculation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6",
   "metadata": {},
   "source": [
    "## 6. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "view-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ICC Statistics:\")\n",
    "print(\"=\" * 60)\n",
    "print(icc_df['ICC'].describe())\n",
    "\n",
    "print(\"\\nTop 20 features by ICC value:\")\n",
    "display(icc_df.sort_values('ICC', ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "icc-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(icc_df['ICC'].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(x=ICC_THRESHOLD, color='r', linestyle='--', linewidth=2, \n",
    "                label=f'Threshold ({ICC_THRESHOLD})')\n",
    "axes[0].set_xlabel('ICC Value', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Distribution of ICC Values', fontsize=14)\n",
    "axes[0].legend()\n",
    "\n",
    "# Category bar chart\n",
    "icc_categories = {\n",
    "    'Poor\\n(<0.5)': (icc_df['ICC'] < 0.5).sum(),\n",
    "    'Moderate\\n(0.5-0.75)': ((icc_df['ICC'] >= 0.5) & (icc_df['ICC'] < 0.75)).sum(),\n",
    "    'Good\\n(0.75-0.9)': ((icc_df['ICC'] >= 0.75) & (icc_df['ICC'] < 0.9)).sum(),\n",
    "    'Excellent\\n(>=0.9)': (icc_df['ICC'] >= 0.9).sum()\n",
    "}\n",
    "\n",
    "colors = ['#ff6b6b', '#ffd93d', '#6bcb77', '#4d96ff']\n",
    "bars = axes[1].bar(icc_categories.keys(), icc_categories.values(), \n",
    "                   color=colors, edgecolor='black')\n",
    "axes[1].set_xlabel('ICC Category', fontsize=12)\n",
    "axes[1].set_ylabel('Number of Features', fontsize=12)\n",
    "axes[1].set_title('Features by ICC Category', fontsize=14)\n",
    "\n",
    "for bar, value in zip(bars, icc_categories.values()):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                 str(value), ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}ICC_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7",
   "metadata": {},
   "source": [
    "## 7. Feature Selection (ICC > 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filter-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features with excellent reproducibility\n",
    "selected_features_df = icc_df[icc_df['ICC'] > ICC_THRESHOLD].copy()\n",
    "selected_features = selected_features_df['Feature'].tolist()\n",
    "\n",
    "print(f\"Feature Selection Results:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Original features: {len(feature_columns)}\")\n",
    "print(f\"Features with ICC > {ICC_THRESHOLD}: {len(selected_features)}\")\n",
    "print(f\"Retention rate: {len(selected_features)/len(feature_columns)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-8",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ICC results\n",
    "icc_df.to_excel(f'{OUTPUT_DIR}ICC_results_all_features.xlsx', index=False)\n",
    "selected_features_df.to_excel(f'{OUTPUT_DIR}ICC_selected_features.xlsx', index=False)\n",
    "pd.DataFrame({'selected_features': selected_features}).to_csv(\n",
    "    f'{OUTPUT_DIR}selected_feature_names.csv', index=False)\n",
    "\n",
    "# Save filtered feature data\n",
    "columns_to_keep = [col for col in ID_COLUMNS + selected_features if col in features_run1.columns]\n",
    "features_filtered = features_run1[columns_to_keep].copy()\n",
    "features_filtered.to_excel(f'{OUTPUT_DIR}features_after_ICC_selection.xlsx', index=False)\n",
    "\n",
    "print(\"Results saved:\")\n",
    "print(f\"  - {OUTPUT_DIR}ICC_results_all_features.xlsx\")\n",
    "print(f\"  - {OUTPUT_DIR}ICC_selected_features.xlsx\")\n",
    "print(f\"  - {OUTPUT_DIR}selected_feature_names.csv\")\n",
    "print(f\"  - {OUTPUT_DIR}features_after_ICC_selection.xlsx\")\n",
    "print(f\"  - {OUTPUT_DIR}ICC_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-9",
   "metadata": {},
   "source": [
    "## 9. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"                ICC Feature Selection Summary Report\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n[Data Overview]\")\n",
    "print(f\"  - Number of samples: {features_run1.shape[0]}\")\n",
    "print(f\"  - Original features: {len(feature_columns)}\")\n",
    "\n",
    "print(f\"\\n[ICC Method]\")\n",
    "print(f\"  - ICC model: ICC(2,1) - Two-way random effects, absolute agreement\")\n",
    "print(f\"  - Tool: pingouin v{pg.__version__}\")\n",
    "print(f\"  - Selection threshold: ICC > {ICC_THRESHOLD}\")\n",
    "\n",
    "print(f\"\\n[ICC Statistics]\")\n",
    "print(f\"  - Mean: {icc_df['ICC'].mean():.4f}\")\n",
    "print(f\"  - Median: {icc_df['ICC'].median():.4f}\")\n",
    "print(f\"  - Std: {icc_df['ICC'].std():.4f}\")\n",
    "print(f\"  - Range: [{icc_df['ICC'].min():.4f}, {icc_df['ICC'].max():.4f}]\")\n",
    "\n",
    "print(f\"\\n[Feature Categories]\")\n",
    "print(f\"  - Poor (ICC < 0.5): {(icc_df['ICC'] < 0.5).sum()}\")\n",
    "print(f\"  - Moderate (0.5 <= ICC < 0.75): {((icc_df['ICC'] >= 0.5) & (icc_df['ICC'] < 0.75)).sum()}\")\n",
    "print(f\"  - Good (0.75 <= ICC < 0.9): {((icc_df['ICC'] >= 0.75) & (icc_df['ICC'] < 0.9)).sum()}\")\n",
    "print(f\"  - Excellent (ICC >= 0.9): {(icc_df['ICC'] >= 0.9).sum()}\")\n",
    "\n",
    "print(f\"\\n[Final Results]\")\n",
    "print(f\"  - Selected features: {len(selected_features)}\")\n",
    "print(f\"  - Retention rate: {len(selected_features)/len(feature_columns)*100:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "notes",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ICC Interpretation Guidelines (Koo & Li, 2016)\n",
    "\n",
    "| ICC Value | Reliability |\n",
    "|-----------|-------------|\n",
    "| < 0.50 | Poor |\n",
    "| 0.50 - 0.75 | Moderate |\n",
    "| 0.75 - 0.90 | Good |\n",
    "| >= 0.90 | Excellent |\n",
    "\n",
    "## References\n",
    "1. Koo TK, Li MY. A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research. J Chiropr Med. 2016;15(2):155-163.\n",
    "2. Shrout PE, Fleiss JL. Intraclass correlations: uses in assessing rater reliability. Psychol Bull. 1979;86(2):420-428."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
